trigger:
  branches:
    include:
      - main
      - release/*

pr:
  branches:
    include:
      - main
      - release/*

pool:
  name: Default

variables:
  - group: databricks-common
  - name: pythonVersion
    value: "3.11"
  - name: CONDA_ACTIVATE
    value: "source ~/anaconda3/etc/profile.d/conda.sh && conda activate base"

stages:
  - stage: CodeQuality
    displayName: "Code Quality"
    jobs:
      - job: LintAndFormat
        displayName: "Lint & Format Check"
        steps:
          - script: |
              $(CONDA_ACTIVATE)
              python -m pip install --upgrade pip
              pip install ruff black isort
            displayName: "Install lint tools"

          - script: |
              $(CONDA_ACTIVATE)
              ruff check src/ tests/ dlt/ --output-format=github
            displayName: "Ruff lint check"

          - script: |
              $(CONDA_ACTIVATE)
              black --check --diff src/ tests/
            displayName: "Black format check"
            continueOnError: true

          - script: |
              $(CONDA_ACTIVATE)
              isort --check-only --diff src/ tests/
            displayName: "isort import order check"
            continueOnError: true

  - stage: UnitTests
    displayName: "Unit Tests"
    dependsOn: CodeQuality
    jobs:
      - job: RunAPITests
        displayName: "Run API & Unit Tests"
        steps:
          - script: |
              $(CONDA_ACTIVATE)
              python -m pip install --upgrade pip
              pip install -r requirements-test.txt
              pip install pytest-html
            displayName: "Install test dependencies"

          - script: |
              $(CONDA_ACTIVATE)
              pytest tests/ \
                --ignore=tests/test_silver_transforms.py \
                --ignore=tests/test_feature_engineering.py \
                --ignore=tests/test_integration.py \
                -v \
                --tb=short \
                --junitxml=$(Build.ArtifactStagingDirectory)/test-results-unit.xml \
                --html=$(Build.ArtifactStagingDirectory)/test-report-unit.html \
                --cov=serving/api \
                --cov=src \
                --cov-report=xml:$(Build.ArtifactStagingDirectory)/coverage-unit.xml \
                --cov-report=html:$(Build.ArtifactStagingDirectory)/coverage-html-unit
            displayName: "Run unit tests (API, schemas, config, risk tiers)"

          - task: PublishTestResults@2
            inputs:
              testResultsFormat: "JUnit"
              testResultsFiles: "$(Build.ArtifactStagingDirectory)/test-results-unit.xml"
              testRunTitle: "Unit Tests"
            displayName: "Publish unit test results"
            condition: always()

          - task: PublishCodeCoverageResults@2
            inputs:
              summaryFileLocation: "$(Build.ArtifactStagingDirectory)/coverage-unit.xml"
            displayName: "Publish code coverage"
            condition: always()

      - job: RunSparkTests
        displayName: "Run PySpark Tests (requires Java)"
        continueOnError: true
        steps:
          - script: |
              $(CONDA_ACTIVATE)
              python -m pip install --upgrade pip
              pip install -r requirements.txt
              pip install pytest pytest-cov pytest-html
            displayName: "Install dependencies"

          - script: |
              $(CONDA_ACTIVATE)
              if ! java -version 2>/dev/null; then
                echo "##[warning]Java not available â€” PySpark tests skipped (run in Databricks)"
                exit 0
              fi
              pytest tests/test_silver_transforms.py tests/test_feature_engineering.py \
                tests/test_integration.py \
                -v \
                --tb=short \
                --junitxml=$(Build.ArtifactStagingDirectory)/test-results-spark.xml \
                --html=$(Build.ArtifactStagingDirectory)/test-report-spark.html
            displayName: "Run PySpark tests (or skip if no Java)"

          - task: PublishTestResults@2
            inputs:
              testResultsFormat: "JUnit"
              testResultsFiles: "$(Build.ArtifactStagingDirectory)/test-results-spark.xml"
              testRunTitle: "PySpark Tests"
            displayName: "Publish PySpark test results"
            condition: always()

  - stage: NotebookValidation
    displayName: "Notebook Validation"
    dependsOn: CodeQuality
    jobs:
      - job: ValidateNotebooks
        displayName: "Validate Databricks Notebooks"
        steps:
          - script: |
              for nb in notebooks/*.py; do
                if head -1 "$nb" | grep -q "# Databricks notebook source"; then
                  echo "  PASS: $nb"
                else
                  echo "  FAIL: $nb (missing Databricks header)"
                  exit 1
                fi
              done
              echo "All notebooks valid."
            displayName: "Validate notebook format"

          - script: |
              $(CONDA_ACTIVATE)
              python -m py_compile src/risk_tiers.py
              python -m py_compile src/__init__.py
              for nb in notebooks/*.py; do
                sed 's/# MAGIC.*//g' "$nb" | python -c "
              import sys, ast
              try:
                  ast.parse(sys.stdin.read())
                  print(f'  PASS: syntax ok')
              except SyntaxError as e:
                  print(f'  WARN: {e}')
              "
              done
            displayName: "Python syntax validation"

  - stage: BuildArtifact
    displayName: "Build Deployment Artifact"
    dependsOn:
      - UnitTests
      - NotebookValidation
    condition: and(succeeded(), eq(variables['Build.SourceBranch'], 'refs/heads/main'))
    jobs:
      - job: PackageArtifact
        displayName: "Package for Deployment"
        steps:
          - script: |
              mkdir -p $(Build.ArtifactStagingDirectory)/release

              cp -r notebooks/ $(Build.ArtifactStagingDirectory)/release/notebooks/
              cp -r dlt/ $(Build.ArtifactStagingDirectory)/release/dlt/
              cp -r src/ $(Build.ArtifactStagingDirectory)/release/src/
              cp -r workflows/ $(Build.ArtifactStagingDirectory)/release/workflows/
              cp -r config/ $(Build.ArtifactStagingDirectory)/release/config/
              cp -r deploy/ $(Build.ArtifactStagingDirectory)/release/deploy/
              cp requirements.txt $(Build.ArtifactStagingDirectory)/release/

              echo "BUILD_ID=$(Build.BuildId)" > $(Build.ArtifactStagingDirectory)/release/BUILD_INFO
              echo "SOURCE_VERSION=$(Build.SourceVersion)" >> $(Build.ArtifactStagingDirectory)/release/BUILD_INFO
              echo "BUILD_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> $(Build.ArtifactStagingDirectory)/release/BUILD_INFO
            displayName: "Package artifact"

          - task: PublishBuildArtifacts@1
            inputs:
              pathToPublish: "$(Build.ArtifactStagingDirectory)/release"
              artifactName: "telco-churn-release"
            displayName: "Publish release artifact"
